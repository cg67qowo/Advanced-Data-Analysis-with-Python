{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Linear Regression for Causal Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is taken (and simplified) from a notebook by Matheus Facture, freely released on his GitHub account under the MIT license: [link](https://github.com/matheusfacure/python-causality-handbook/blob/master/causal-inference-for-the-brave-and-true). All credits to the author!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import graphviz as gr\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>asian</th>\n",
       "      <th>black</th>\n",
       "      <th>hawaiian</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>unknown</th>\n",
       "      <th>white</th>\n",
       "      <th>format_ol</th>\n",
       "      <th>format_blended</th>\n",
       "      <th>falsexam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.29997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.96000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83.37000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.01994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.30000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  asian  black  hawaiian  hispanic  unknown  white  format_ol  \\\n",
       "0       0    0.0    0.0       0.0       0.0      0.0    1.0          0   \n",
       "1       1    0.0    0.0       0.0       0.0      0.0    1.0          0   \n",
       "2       1    0.0    0.0       0.0       0.0      0.0    1.0          0   \n",
       "3       1    0.0    0.0       0.0       0.0      0.0    1.0          0   \n",
       "4       1    0.0    0.0       0.0       0.0      0.0    1.0          1   \n",
       "\n",
       "   format_blended  falsexam  \n",
       "0             0.0  63.29997  \n",
       "1             0.0  79.96000  \n",
       "2             1.0  83.37000  \n",
       "3             1.0  90.01994  \n",
       "4             0.0  83.30000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/matheusfacure/python-causality-handbook/refs/heads/master/causal-inference-for-the-brave-and-true/data/online_classroom.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   77.8555</td> <td>    0.762</td> <td>  102.235</td> <td> 0.000</td> <td>   76.357</td> <td>   79.354</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>format_ol</th> <td>   -4.2203</td> <td>    1.412</td> <td>   -2.990</td> <td> 0.003</td> <td>   -6.998</td> <td>   -1.443</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lcccccc}\n",
       "\\toprule\n",
       "                    & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}  &      77.8555  &        0.762     &   102.235  &         0.000        &       76.357    &       79.354     \\\\\n",
       "\\textbf{format\\_ol} &      -4.2203  &        1.412     &    -2.990  &         0.003        &       -6.998    &       -1.443     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = smf.ols('falsexam ~ format_ol', data=data).fit()\n",
    "result.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's quite amazing. We are not only able to estimate the ATE, but we also get, for free, confidence intervals and P-Values out of it! More than that, we can see that regression is doing exactly what it supposed to do: comparing $E[Y|T=0]$ and $E[Y|T=1]$. The intercept is exactly the sample mean when $T=0$, $E[Y|T=0]$, and the coefficient of the online format is exactly the sample difference in means $E[Y|T=1] - E[Y|T=0]$. Don't trust me? No problem. You can see for yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "format_ol\n",
       "0    77.855523\n",
       "1    73.635263\n",
       "Name: falsexam, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data\n",
    " .groupby(\"format_ol\")\n",
    " [\"falsexam\"]\n",
    " .mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected. If you add to the intercept the ATE, that is, the parameter estimate of online format, you get the sample mean for the treated: $78.5475 + (-4.9122) = 73.635263$.\n",
    "\n",
    "## Regression Theory\n",
    "\n",
    "I don't intend to dive too deep into how linear regression is constructed and estimated. However, a little bit of theory will go a long way in explaining its power in causal inference. First of all, regression solves a theoretical best linear prediction problem. Let $\\beta^*$ be a vector of parameters:\n",
    "\n",
    "$\n",
    "\\beta^* =\\underset{\\beta}{argmin} \\ E[(Y_i - X_i'\\beta)^2]\n",
    "$\n",
    "\n",
    "Linear regression finds the parameters that minimise the mean squared error (MSE). \n",
    "\n",
    "If you differentiate it and set it to zero, you will find that the linear solution to this problem is given by\n",
    "\n",
    "$\n",
    "\\beta^* = E[X_i'X_i]^{-1}E[X_i' Y_i]\n",
    "$\n",
    "\n",
    "We can estimate this beta using the sample equivalent:\n",
    "\n",
    "$\n",
    "\\hat{\\beta} = (X'X)^{-1}X' Y\n",
    "$\n",
    "\n",
    "But don't take my word for it. If you are one of those that understand code better than formulas, try for yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.22026036, 77.85552345])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[[\"format_ol\"]].assign(intercep=1)\n",
    "y = data[\"falsexam\"]\n",
    "\n",
    "def regress(y, X): \n",
    "    return np.linalg.inv(X.T.dot(X)).dot(X.T.dot(y))\n",
    "\n",
    "beta = regress(y, X)\n",
    "beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formulas above are pretty general. However, it pays off to study the case where we only have one regressor. In causal inference, we often want to estimate the causal impact of a variable $T$ on an outcome $y$. So, we use regression with this single variable to estimate this effect. Even if we include other variables in the model, they are usually just auxiliary. Adding other variables can help us estimate the causal effect of the treatment, but we are not very interested in estimating their parameters. \n",
    "\n",
    "With a single regressor variable $T$, the parameter associated to it will be given by\n",
    "\n",
    "$\n",
    "\\beta_1 = \\dfrac{Cov(Y_i, T_i)}{Var(T_i)} \n",
    "$\n",
    "\n",
    "If $T$ is randomly assigned, $\\beta_1$ is the ATE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-4.220260364675276)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kapa = data[\"falsexam\"].cov(data[\"format_ol\"]) / data[\"format_ol\"].var()\n",
    "kapa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have more than one regressor, we can extend the following formula to accommodate that. Let's say those other variables are just auxiliary and that we are truly interested only in estimating the parameter $\\kappa$ associated to $T$.\n",
    "\n",
    "$\n",
    "y_i = \\beta_0 + \\kappa T_i + \\beta_1 X_{1i} + ... +\\beta_k X_{ki} + u_i\n",
    "$\n",
    "\n",
    "$\\kappa$ can be obtained with the following formula\n",
    "\n",
    "$\n",
    "\\kappa = \\dfrac{Cov(Y_i, \\tilde{T_i})}{Var(\\tilde{T_i})} \n",
    "$\n",
    "\n",
    "where $\\tilde{T_i}$ is the residual from a regression of $T_i$ on all other covariates $X_{1i}, ..., X_{ki}$. Now, let's appreciate how cool this is. It means that the coefficient of a multivariate regression is the bivariate coefficient of the same regressor **after accounting for the effect of other variables in the model**. In causal inference terms, $\\kappa$ is the bivariate coefficient of $T$ after having used all other variables to predict it.\n",
    "\n",
    "This has a nice intuition behind it. If we can predict $T$ using other variables, it means it's not random. However, we can make it so that $T$ is as good as random once we control for other available variables. To do so, we use linear regression to predict it from the other variables and then we take the residuals of that regression $\\tilde{T}$. By definition, $\\tilde{T}$ cannot be predicted by the other variables $X$ that we've already used to predict $T$. Quite elegantly, $\\tilde{T}$ is a version of the treatment that is not associated with any other variable in $X$.\n",
    "\n",
    "By the way, this is also a property of linear regression. The residual are always orthogonal or uncorrelated with any of the variables in the model that created it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orthogonality imply that the dot product is zero: [2.16004992e-12 5.88329385e-12]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format_ol</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>format_ol</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.977210e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>2.977210e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              format_ol             e\n",
       "format_ol  1.000000e+00  2.977210e-16\n",
       "e          2.977210e-16  1.000000e+00"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = y - X.dot(beta)\n",
    "print(\"Orthogonality imply that the dot product is zero:\", np.dot(e, X))\n",
    "X[[\"format_ol\"]].assign(e=e).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what is even cooler is that these properties don't depend on anything! They are mathematical truths, regardless of what your data looks like.\n",
    "\n",
    "## Regression For Non-Random Data\n",
    "\n",
    "So far, we worked with random experiment data but, as we know, those are hard to come by. Experiments are very expensive to conduct or simply infeasible. It's very hard to convince McKinsey & Co. to randomly provide their services free of charge so that we can, once and for all, distinguish the value their consulting services brings from the fact that those firms that can afford to pay them are already very well off.\n",
    "\n",
    "\n",
    "For this reason, we shall now delve into non random or observational data. In the following example, we will try to estimate the impact of an additional year of education on hourly wage. As you might have guessed, it is extremely hard to conduct an experiment with education. You can't simply randomize people to 4, 8 or 12 years of education. In this case observational data is all we have.\n",
    "\n",
    "First, let's estimate a very simple model. We will regress log hourly wages on years of education. We use logs here so that our parameter estimates have a percentage interpretation (if you never heard about this amazing properties of the log and want to know why that is, check out [this link](https://stats.stackexchange.com/questions/244199/why-is-it-that-natural-log-changes-are-percentage-changes-what-is-about-logs-th)). With it, we will be able to say that 1 extra year of education yields a wage increase of x%. \n",
    "\n",
    "\n",
    "$\n",
    "log(hwage)_i = \\beta_0 + \\beta_1 educ_i + u_i\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/wage.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m wage = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./data/wage.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.dropna()\n\u001b[32m      2\u001b[39m model_1 = smf.ols(\u001b[33m'\u001b[39m\u001b[33mnp.log(hwage) ~ educ\u001b[39m\u001b[33m'\u001b[39m, data=wage.assign(hwage=wage[\u001b[33m\"\u001b[39m\u001b[33mwage\u001b[39m\u001b[33m\"\u001b[39m]/wage[\u001b[33m\"\u001b[39m\u001b[33mhours\u001b[39m\u001b[33m\"\u001b[39m])).fit()\n\u001b[32m      3\u001b[39m model_1.summary().tables[\u001b[32m1\u001b[39m] \u001b[38;5;66;03m# The second tables contains regression coefficients\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/transf_env/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/transf_env/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/transf_env/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/transf_env/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/transf_env/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './data/wage.csv'"
     ]
    }
   ],
   "source": [
    "wage = pd.read_csv(\"./data/wage.csv\").dropna()\n",
    "model_1 = smf.ols('np.log(hwage) ~ educ', data=wage.assign(hwage=wage[\"wage\"]/wage[\"hours\"])).fit()\n",
    "model_1.summary().tables[1] # The second tables contains regression coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimate of $\\beta_1$ is 0.0536, with a 95% confidence interval of (0.039, 0.068). This means that this model predicts that wages will increase about 5.3% for every additional year of education. This percentage increase is inline with the belief that education impacts wages in an exponential fashion: we expect that going from 11 to 12 years of education (average to graduate high school) to be less rewarding than going from 14 to 16 years (average to graduate college)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use(\"fivethirtyeight\")\n",
    "\n",
    "x = np.array(range(5, 20))\n",
    "plt.plot(x, np.exp(model_1.params[\"Intercept\"] + model_1.params[\"educ\"] * x))\n",
    "plt.xlabel(\"Years of Education\")\n",
    "plt.ylabel(\"Hourly Wage\")\n",
    "plt.title(\"Impact of Education on Hourly Wage\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, it is not because we can estimate this simple model that it's correct. Notice how I was carefully with my words saying it **predicts** wage from education. I never said that this prediction was causal. In fact, by now, you probably have very serious reasons to believe this model is biased. Since our data didn't come from a random experiment, we don't know if those that got more education are comparable to those who got less. Going even further, from our understanding of how the world works, we are very certain that they are not comparable. Namely, we can argue that those with more years of education probably have richer parents, and that the increase we are seeing in wages as we increase education is just a reflection of how the family wealth is associated with more years of education. Putting it in math terms, we think that $E[Y_0|T=0] < E[Y_0|T=1]$, that is, those with more education would have higher income anyway, even without so many years of education. If you are really grim about education, you can argue that it can even *reduce* wages by keeping people out of the workforce and lowering their experience.\n",
    "\n",
    "Fortunately, in our data, we have access to lots of other variables. We can see the parents' education `meduc`, `feduc`, the `IQ` score for that person, the number of years of experience `exper` and the tenure of the person in his or her current company `tenure`. We even have some dummy variables for marriage and black ethnicity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage</th>\n",
       "      <th>hours</th>\n",
       "      <th>lhwage</th>\n",
       "      <th>IQ</th>\n",
       "      <th>educ</th>\n",
       "      <th>exper</th>\n",
       "      <th>tenure</th>\n",
       "      <th>age</th>\n",
       "      <th>married</th>\n",
       "      <th>black</th>\n",
       "      <th>south</th>\n",
       "      <th>urban</th>\n",
       "      <th>sibs</th>\n",
       "      <th>brthord</th>\n",
       "      <th>meduc</th>\n",
       "      <th>feduc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>769</td>\n",
       "      <td>40</td>\n",
       "      <td>2.956212</td>\n",
       "      <td>93</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>825</td>\n",
       "      <td>40</td>\n",
       "      <td>3.026504</td>\n",
       "      <td>108</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>650</td>\n",
       "      <td>40</td>\n",
       "      <td>2.788093</td>\n",
       "      <td>96</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>562</td>\n",
       "      <td>40</td>\n",
       "      <td>2.642622</td>\n",
       "      <td>74</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>600</td>\n",
       "      <td>40</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>91</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wage  hours    lhwage   IQ  educ  exper  tenure  age  married  black  \\\n",
       "0   769     40  2.956212   93    12     11       2   31        1      0   \n",
       "2   825     40  3.026504  108    14     11       9   33        1      0   \n",
       "3   650     40  2.788093   96    12     13       7   32        1      0   \n",
       "4   562     40  2.642622   74    11     14       5   34        1      0   \n",
       "6   600     40  2.708050   91    10     13       0   30        0      0   \n",
       "\n",
       "   south  urban  sibs  brthord  meduc  feduc  \n",
       "0      0      1     1      2.0    8.0    8.0  \n",
       "2      0      1     1      2.0   14.0   14.0  \n",
       "3      0      1     4      3.0   12.0   12.0  \n",
       "4      0      1    10      6.0    6.0   11.0  \n",
       "6      0      1     1      2.0    8.0    8.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wage.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can include all those extra variables in a model and estimate it:\n",
    "\n",
    "$\n",
    "log(hwage)_i = \\beta_0 + \\kappa \\ educ_i + \\pmb{\\beta}X_i + u_i\n",
    "$\n",
    "\n",
    "To understand how this helps with the bias problem, let's recap the bivariate breakdown of multivariate linear regression.\n",
    "\n",
    "$\n",
    "\\kappa = \\dfrac{Cov(Y_i, \\tilde{T_i})}{Var(\\tilde{T_i})} \n",
    "$\n",
    "\n",
    "This formula says that we can predict `educ` from the parents' education, from IQ, from experience and so on. After we do that, we'll be left with a version of `educ`, $\\tilde{educ}$, which is uncorrelated with all the variables included previously. This will break down arguments such as \"people that have more years of education have it because they have higher IQ. It is not the case that education leads to higher wages. It is just the case that it is correlated with IQ, which is what drives wages\". Well, if we include IQ in our model, then $\\kappa$ becomes the return of an additional year of education while keeping IQ fixed. Pause a little bit to understand what this implies. Even if we can't use randomised controlled trials to keep other factors equal between treated and untreated, regression can do this by including those same factors in the model, even if the data is not random!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.041147191010057635"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controls = ['IQ', 'exper', 'tenure', 'age', 'married', 'black',\n",
    "            'south', 'urban', 'sibs', 'brthord', 'meduc', 'feduc']\n",
    "\n",
    "X = wage[controls].assign(intercep=1)\n",
    "t = wage[\"educ\"]\n",
    "y = wage[\"lhwage\"]\n",
    "\n",
    "beta_aux = regress(t, X)\n",
    "t_tilde = t - X.dot(beta_aux)\n",
    "\n",
    "kappa = t_tilde.cov(y) / t_tilde.var()\n",
    "kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This coefficient we've just estimated tells us that, for people with the same IQ, experience, tenure, age and so on, we should expect an additional year of education to be associated with a 4.11% increase in hourly wage. This confirms our suspicion that the first simple model with only `educ` was biased. It also confirms that this bias was overestimating the impact of education. Once we controlled for other factors, the estimated impact of education fell.\n",
    "\n",
    "If we are wiser and use software that other people wrote instead of coding everything yourself, we can even place a confidence interval around this estimate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    1.1156</td> <td>    0.232</td> <td>    4.802</td> <td> 0.000</td> <td>    0.659</td> <td>    1.572</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ</th>      <td>    0.0411</td> <td>    0.010</td> <td>    4.075</td> <td> 0.000</td> <td>    0.021</td> <td>    0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IQ</th>        <td>    0.0038</td> <td>    0.001</td> <td>    2.794</td> <td> 0.005</td> <td>    0.001</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exper</th>     <td>    0.0153</td> <td>    0.005</td> <td>    3.032</td> <td> 0.003</td> <td>    0.005</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>    <td>    0.0094</td> <td>    0.003</td> <td>    2.836</td> <td> 0.005</td> <td>    0.003</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>       <td>    0.0086</td> <td>    0.006</td> <td>    1.364</td> <td> 0.173</td> <td>   -0.004</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>married</th>   <td>    0.1795</td> <td>    0.053</td> <td>    3.415</td> <td> 0.001</td> <td>    0.076</td> <td>    0.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>     <td>   -0.0801</td> <td>    0.063</td> <td>   -1.263</td> <td> 0.207</td> <td>   -0.205</td> <td>    0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>south</th>     <td>   -0.0397</td> <td>    0.035</td> <td>   -1.129</td> <td> 0.259</td> <td>   -0.109</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>urban</th>     <td>    0.1926</td> <td>    0.036</td> <td>    5.418</td> <td> 0.000</td> <td>    0.123</td> <td>    0.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sibs</th>      <td>    0.0065</td> <td>    0.009</td> <td>    0.722</td> <td> 0.470</td> <td>   -0.011</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>brthord</th>   <td>   -0.0080</td> <td>    0.013</td> <td>   -0.604</td> <td> 0.546</td> <td>   -0.034</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>meduc</th>     <td>    0.0089</td> <td>    0.007</td> <td>    1.265</td> <td> 0.206</td> <td>   -0.005</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>feduc</th>     <td>    0.0069</td> <td>    0.006</td> <td>    1.113</td> <td> 0.266</td> <td>   -0.005</td> <td>    0.019</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = smf.ols('lhwage ~ educ +' + '+'.join(controls), data=wage).fit()\n",
    "model_2.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, back to our question, is the parameter we've estimated for the impact of `educ` on wage causal? I'm sorry to bring it to you, but that will depend on our ability to argue in favor or against that fact that all confounders have been included in the model. Personally, I think they haven't. For instance, we haven't included family wealth. Even if we included family education, that can only be seen as a proxy for wealth. We've also not accounted for factors like personal ambition. It could be that ambition is what causes both more years of education and higher wage, so it is a confounder. This is to show that **causal inference with non-random or observational data should always be taken with a grain of salt**. We can never be sure that all confounders were accounted for.\n",
    "\n",
    "## References\n",
    "\n",
    "I like to think of this entire book as a tribute to Joshua Angrist, Alberto Abadie and Christopher Walters for their amazing Econometrics class. Most of the ideas here are taken from their classes at the American Economic Association. Watching them is what is keeping me sane during this tough year of 2020.\n",
    "* [Cross-Section Econometrics](https://www.aeaweb.org/conference/cont-ed/2017-webcasts)\n",
    "* [Mastering Mostly Harmless Econometrics](https://www.aeaweb.org/conference/cont-ed/2020-webcasts)\n",
    "\n",
    "I'll also like to reference the amazing books from Angrist. They have shown me that Econometrics, or 'Metrics as they call it, is not only extremely useful but also profoundly fun.\n",
    "\n",
    "* [Mostly Harmless Econometrics](https://www.mostlyharmlesseconometrics.com/)\n",
    "* [Mastering 'Metrics](https://www.masteringmetrics.com/)\n",
    "\n",
    "My final reference is Miguel Hernan and Jamie Robins' book. It has been my trustworthy companion in the most thorny causal questions I had to answer.\n",
    "\n",
    "* [Causal Inference Book](https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/)\n",
    "\n",
    "![img](./data/img/poetry.png)\n",
    "\n",
    "\n",
    "## Contribute\n",
    "\n",
    "Causal Inference for the Brave and True is an open-source material on causal inference, the statistics of science. It uses only free software, based in Python. Its goal is to be accessible monetarily and intellectually.\n",
    "If you found this book valuable and you want to support it, please go to [Patreon](https://www.patreon.com/causal_inference_for_the_brave_and_true). If you are not ready to contribute financially, you can also help by fixing typos, suggesting edits or giving feedback on passages you didn't understand. Just go to the book's repository and [open an issue](https://github.com/matheusfacure/python-causality-handbook/issues). Finally, if you liked this content, please share it with others who might find it useful and give it a [star on GitHub](https://github.com/matheusfacure/python-causality-handbook/stargazers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "transf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
